{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "qualified-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-museum",
   "metadata": {},
   "source": [
    "### Download the IRIS data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(filename, source = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confident-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.read_csv('iris.data', sep =' ', delimiter = ',', names = ['s_length', 's_width', 'p_length', 'p_width', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-greenhouse",
   "metadata": {},
   "source": [
    "### Split the data set into training/test data as follows: use the first 35 points in each class for training, and use the remaining 15 points for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seventh-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = pd.DataFrame(pd_data.iloc[0:35, :])\n",
    "df2 = pd.DataFrame(pd_data.iloc[50:85, :])\n",
    "df3 = pd.DataFrame(pd_data.iloc[100:135, :])\n",
    "df_train_data = df_train_data.append(df2)\n",
    "df_train_data = df_train_data.append(df3)\n",
    "\n",
    "df_test_data = pd.DataFrame(pd_data.iloc[35:50, :])\n",
    "df4 = pd.DataFrame(pd_data.iloc[85:100, :])\n",
    "df5 = pd.DataFrame(pd_data.iloc[135:150, :])\n",
    "df_test_data = df_test_data.append(df4)\n",
    "df_test_data = df_test_data.append(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sufficient-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = df_train_data.iloc[:,0:4]\n",
    "y_train_label = df_train_data.iloc[:,4]\n",
    "\n",
    "x_test_data = df_test_data.iloc[:,0:4]\n",
    "y_test_label = df_test_data.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funky-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data.reset_index(drop = True, inplace = True)\n",
    "y_train_label.reset_index(drop = True, inplace = True)\n",
    "\n",
    "x_test_data.reset_index(drop = True, inplace = True)\n",
    "y_test_label.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reported-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data = y_train_label.astype('category').cat.codes\n",
    "y_test_data = y_test_label.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respective-prerequisite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_data:\n",
      " (105, 4)\n",
      "\n",
      "Shape of y_train_data:\n",
      " (105,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train_data:\\n', x_train_data.shape)\n",
    "print('\\nShape of y_train_data:\\n', y_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "combined-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test_data:\n",
      " (45, 4)\n",
      "\n",
      "Shape of y_test_data:\n",
      " (45,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_test_data:\\n', x_test_data.shape)\n",
    "print('\\nShape of y_test_data:\\n', y_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-affiliation",
   "metadata": {},
   "source": [
    "### Build a classifier for this data set, based on multivariabte Gaussian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upset-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multivariabte Gaussian model\n",
    "def MultivariateGaussian(x, y):\n",
    "    #labels 1,2,...,k\n",
    "    k = 3\n",
    "    \n",
    "    #number of features\n",
    "    d = x.shape[1]\n",
    "    \n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    \n",
    "    for label in range(k):\n",
    "        indices = np.where(y == label)\n",
    "        indices = indices[0]\n",
    "        mu[label] = np.mean(x[indices,:], axis = 0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar = 0, bias = 1)\n",
    "        pi[label] = float(len(indices))/float(len(y))\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "broke-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mu, sigma, and pi\n",
    "mu, sigma, pi = MultivariateGaussian(np.asarray(x_train_data), np.asarray(y_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attractive-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class probabilities:\n",
      " [0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "print('Class probabilities:\\n', pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "packed-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the corresponding data points:\n",
      "  [[5.04571429 3.46857143 1.47714286 0.24      ]\n",
      " [6.00857143 2.76857143 4.31428571 1.34285714]\n",
      " [6.61714286 2.93714286 5.62571429 1.97714286]]\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the corresponding data points:\\n ', mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "illegal-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of the corresponding data points:\n",
      "  [[[ 0.12762449  0.09972245  0.01333061  0.01445714]\n",
      "  [ 0.09972245  0.13644082 -0.0012898   0.01411429]\n",
      "  [ 0.01333061 -0.0012898   0.02919184  0.00462857]\n",
      "  [ 0.01445714  0.01411429  0.00462857  0.0104    ]]\n",
      "\n",
      " [[ 0.27678367  0.09284082  0.17644898  0.0544898 ]\n",
      "  [ 0.09284082  0.09929796  0.08330612  0.04391837]\n",
      "  [ 0.17644898  0.08330612  0.21722449  0.07853061]\n",
      "  [ 0.0544898   0.04391837  0.07853061  0.04530612]]\n",
      "\n",
      " [[ 0.47056327  0.12622041  0.37013061  0.04582041]\n",
      "  [ 0.12622041  0.11890612  0.09247347  0.04627755]\n",
      "  [ 0.37013061  0.09247347  0.35733878  0.05773061]\n",
      "  [ 0.04582041  0.04627755  0.05773061  0.07262041]]]\n"
     ]
    }
   ],
   "source": [
    "print('Covariance of the corresponding data points:\\n ', sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dominant-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify funtion using Bayes' rule\n",
    "def decision(x, pi, mu, sigma): \n",
    "    prob = np.zeros((3, x.shape[0]))\n",
    "    \n",
    "    for i in range (0,3):\n",
    "        prob[i,:] = pi[i]* multivariate_normal.pdf(x, mean = mu[i,:], cov = sigma[i,:,:])                                             \n",
    "    \n",
    "    pred = np.argmax(prob, axis = 0)\n",
    "\n",
    "    return pred, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-giant",
   "metadata": {},
   "source": [
    "### What error rate do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "practical-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on the test data set:\n",
      "0.0%\n"
     ]
    }
   ],
   "source": [
    "# calculate the error rate on the test data set\n",
    "accuracy = np.mean(decision(x_test_data, pi, mu, sigma)[0] == y_test_data)\n",
    "error_rate = (1 - accuracy)*100\n",
    "\n",
    "print('Error rate on the test data set:\\n{}%'.format(error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-specific",
   "metadata": {},
   "source": [
    "### Conclusion: For this data set, we get 100% accuracy with 0.0% error rate on this test data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
