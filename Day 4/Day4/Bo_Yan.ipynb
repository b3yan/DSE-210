{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSE 10 Homework 4 - Due 02/05/2021 9:00am\n",
    "\n",
    "## Instructions\n",
    "* Please upload all work to gradescope by the due date - **late work will not be graded**\n",
    "    * You should submit a single ipynb file containing all your code and output (plots, numeric values, etc...)\n",
    "    * Important: **name your ipynb file according to the following convention**: `<lastname>_<firstname>.ipynb` - example: (`thomas_anthony.ipynb`)\n",
    "    * Please organize your notebook into sections by problem\n",
    "    * Use print statements to clearly indicate which question you are ansering\n",
    "        * Good: `print(\"Problem 4 (e): {}\".format(np.pi))`\n",
    "        * Good: `print(\"The value of pi is: {}\".format(np.pi))`\n",
    "        * Bad:  `print(np.pi)`\n",
    "        * Bad:  `np.pi`\n",
    "    * Use relative paths to load data:\n",
    "        * Good: `loadmnist(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\")`\n",
    "        * Bad: `loadmnist(\"/home/anthony/class/DSE10/train-images-idx3-ubyte\", ...)`\n",
    "* Collaboration is encouraged, but all submissions should be in your own writing/code and written with your own understanding\n",
    "* Your code must run and be able to reproduce your answers\n",
    "* Unless stated otherwise in the assignemnt, your code should use only basic low-level NumPy/SciPy linear algebra and satistics commands (e.g. do not use built in estimation tools or anything from SciKitLearn). When in doubt, ask for clarification on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gzip\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "import operator\n",
    "import bz2\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from pylab import rcParams\n",
    "from struct import unpack\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 9 Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text classification using multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) For this problem, you’ll be using the 20 Newsgroups data set. There are several versions of it on the web. You should download “20news-bydate.tar.gz” from\n",
    "                               http://qwone.com/~jason/20Newsgroups/\n",
    "#### Unpack it and look through the directories at some of the files. Overall, there are roughly 19,000 documents, each from one of 20 newsgroups. The label of a document is the identity of its newsgroup. The documents are divided into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(filename, source = 'http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "    \n",
    "def load_data(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset = 16)\n",
    "    return data / np.float32(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroup_data = load_data('20news-bydate.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) The same website has a processed version of the data, “20news-bydate-matlab.tgz”, that is par- ticularly convenient to use. Download this and also the file “vocabulary.txt”. Look at the first training document in the processed set and the corresponding original text document to under- stand the relation between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('20news-bydate 2/matlab/train.data', header = None, sep =' ')\n",
    "train_label = pd.read_csv('20news-bydate 2/matlab/train.label', header = None, sep = ' ')\n",
    "train_map = pd.read_csv('20news-bydate 2/matlab/train.map', header = None, sep = ' ')\n",
    "test_data = pd.read_csv('20news-bydate 2/matlab/test.data', header = None, sep =' ')\n",
    "test_label = pd.read_csv('20news-bydate 2/matlab/test.label', header = None, sep =' ')\n",
    "test_map = pd.read_csv('20news-bydate 2/matlab/test.map', header = None, sep = ' ')\n",
    "vocabulary_data = pd.read_csv('vocabulary.txt', names = ['word'], header = None, sep =' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) The words in the documents constitute an overall vocabulary V of size 61188. Build a multinomial Naive Bayes model using the training data. For each of the 20 classes j = 1, 2, . . . , 20, you must have the following:\n",
    "\n",
    "    • pij, the fraction of documents that belong to that class; and\n",
    "    • Pj, a probability distribution over V that models the documents of that class.\n",
    "    \n",
    "#### In order to fit Pj, imagine that all the documents of class j are strung together. For each word w 2 V , let Pjw be the fraction of this concatenated document occupied by w. Well, almost: you will need to do smoothing (just add one to the count of how often w occurs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data, y_train_label, x_test_data, y_test_label = train_data, train_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data.columns = ['docIdx', 'wordIdx', 'count']\n",
    "y_train_label['docIdx'] = range(1, len(y_train_label) + 1)\n",
    "y_train_label.columns = ['class', 'docIdx']\n",
    "x_train_data = x_train_data.merge(y_train_label, how = 'left', on = 'docIdx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_data.columns = ['docIdx', 'wordIdx', 'count']\n",
    "y_test_label['docIdx'] = range(1, len(y_test_label) + 1)\n",
    "y_test_label.columns = ['class', 'docIdx']\n",
    "x_test_data = x_test_data.merge(y_test_label, how = 'left',on = 'docIdx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of documents in each class:\n",
      " [0.04259473 0.05155737 0.05075872 0.0520898  0.05102494 0.0525335\n",
      " 0.05164611 0.0525335  0.05288846 0.05271098 0.05306593 0.05271098\n",
      " 0.05244476 0.05271098 0.05262224 0.05315467 0.04836277 0.05004881\n",
      " 0.0411749  0.03336587]\n"
     ]
    }
   ],
   "source": [
    "# calculate pi\n",
    "pi = np.zeros(20)\n",
    "for j in range(20):\n",
    "    pi[j] = np.sum(y_train_label.iloc[:,0] == j + 1)/len(y_train_label)\n",
    "    \n",
    "print('Fraction of documents in each class:\\n', pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution:\n",
      " [[6.66666667e-05 3.04761905e-04 1.31428571e-03 ... 4.76190476e-06\n",
      "  4.76190476e-06 4.76190476e-06]\n",
      " [3.55589754e-04 3.49760414e-04 5.82934024e-06 ... 5.82934024e-06\n",
      "  5.82934024e-06 5.82934024e-06]\n",
      " [7.89707479e-05 4.60662696e-04 6.58089566e-06 ... 6.58089566e-06\n",
      "  6.58089566e-06 6.58089566e-06]\n",
      " ...\n",
      " [3.48108977e-05 4.90517195e-04 3.16462706e-06 ... 3.16462706e-06\n",
      "  3.16462706e-06 3.16462706e-06]\n",
      " [4.03854386e-06 1.61541755e-04 4.03854386e-06 ... 4.03854386e-06\n",
      "  4.03854386e-06 4.03854386e-06]\n",
      " [5.54680393e-06 2.55152981e-04 5.54680393e-05 ... 5.54680393e-06\n",
      "  5.54680393e-06 5.54680393e-06]]\n"
     ]
    }
   ],
   "source": [
    "# calculate p\n",
    "total = vocabulary_data.shape[0]\n",
    "p = np.zeros((20,total ))\n",
    "\n",
    "for j in range(20):\n",
    "    tmp = x_train_data[x_train_data['class'] == j + 1]\n",
    "    p[j,:] = 1   \n",
    "    for i in range(tmp.shape[0]):  \n",
    "        wdidx = tmp['wordIdx'].iloc[i]\n",
    "        count = tmp['count'].iloc[i]\n",
    "        p[j, wdidx - 1] += count\n",
    "    p[j,:] = p[j,:]/np.sum(p[j,:])\n",
    "    \n",
    "print('Probability Distribution:\\n', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Write a routine that uses this naive Bayes model to classify a new document. To avoid underflow, work with logs rather than multiplying together probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision(x_test_data, pi, p):\n",
    "    wdidx = x_test_data['wordIdx']\n",
    "    prob = [np.log(pi[j]) + np.sum(x_test_data['count'] * np.log(p[j,wdidx - 1 ])) for j in range(20)]\n",
    "    pred = np.argmax(prob)\n",
    "        \n",
    "    return pred , prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Evaluate the performance of your model on the test data. What error rate do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of naive Bayes model is:\n",
      "21.892071952031976%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(y_test_label.shape[0]):\n",
    "    x_test = x_test_data.loc[x_test_data['docIdx'] == i + 1,:]\n",
    "    pred, prob = decision(x_test, pi, p)\n",
    "    result.append(pred + 1 != y_test_label['class'].iloc[i])\n",
    "    \n",
    "# calculate the error rate of naive Bayes model\n",
    "error_rate = np.mean(result) * 100\n",
    "print('Error rate of naive Bayes model is:\\n{}%'.format(error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Split the training data into a smaller training set and a validation set. The split could be 80-20, for instance. You’ll use this training set to estimate parameters and the validation set to decide between different options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = x_train_data, y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_set:\n",
      " (1173876, 4)\n",
      "\n",
      "Shape of y_train_set:\n",
      " (9087, 2)\n"
     ]
    }
   ],
   "source": [
    "# randomly select 80% data from data set as training data set.\n",
    "count = int(x.shape[0]*0.8)\n",
    "random.seed(10)\n",
    "sel = random.sample(range (0, x.shape[0]),  count)\n",
    "x_train_set, y_train_set = x_train_data.loc[x_train_data.index.intersection(sel),:], y_train_label.loc[y_train_label.index.intersection(sel),:]\n",
    "\n",
    "print('Shape of x_train_set:\\n', x_train_set.shape)\n",
    "print('\\nShape of y_train_set:\\n', y_train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_validation_set:\n",
      " (293469, 4)\n",
      "\n",
      "Shape of y_validation_set:\n",
      " (2182, 2)\n"
     ]
    }
   ],
   "source": [
    "# get the remaining data as validation data set.\n",
    "remain = np.setdiff1d(range(0, x.shape[0]), sel)\n",
    "x_validation_set, y_validation_set = x_train_data.loc[x_train_data.index.intersection(remain),], y_train_label.iloc[y_train_label.index.intersection(remain),]\n",
    "\n",
    "print('Shape of x_validation_set:\\n', x_validation_set.shape)\n",
    "print('\\nShape of y_validation_set:\\n', y_validation_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (i) replacing the frequency f of a word in a document by log(1 + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of documents in each class:\n",
      " [0.0432486  0.05051172 0.05150215 0.05227248 0.05216243 0.05172224\n",
      " 0.05271267 0.05227248 0.05249257 0.05238252 0.05425333 0.053483\n",
      " 0.0532629  0.05216243 0.05205238 0.05172224 0.04842082 0.04963134\n",
      " 0.04071751 0.0330142 ]\n"
     ]
    }
   ],
   "source": [
    "# calculate pi_f\n",
    "pi_f = np.zeros(20)\n",
    "for j in range(20):\n",
    "    pi_f[j] = np.sum(y_train_set.iloc[:,0] == j + 1)/len(y_train_set)\n",
    "    \n",
    "print('Fraction of documents in each class:\\n', pi_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution:\n",
      " [[7.77168995e-05 2.38701906e-04 1.29343126e-03 ... 5.55120711e-06\n",
      "  5.55120711e-06 5.55120711e-06]\n",
      " [4.04435307e-04 2.83104715e-04 6.74058845e-06 ... 6.74058845e-06\n",
      "  6.74058845e-06 6.74058845e-06]\n",
      " [8.21925997e-05 3.88546835e-04 7.47205452e-06 ... 7.47205452e-06\n",
      "  7.47205452e-06 7.47205452e-06]\n",
      " ...\n",
      " [4.13868352e-05 4.74067385e-04 3.76243957e-06 ... 3.76243957e-06\n",
      "  3.76243957e-06 3.76243957e-06]\n",
      " [4.74858611e-06 1.28211825e-04 4.74858611e-06 ... 4.74858611e-06\n",
      "  4.74858611e-06 4.74858611e-06]\n",
      " [6.37897490e-06 2.74295921e-04 5.10317992e-05 ... 6.37897490e-06\n",
      "  6.37897490e-06 6.37897490e-06]]\n"
     ]
    }
   ],
   "source": [
    "# calculate p_f\n",
    "p_f = np.zeros((20,total))\n",
    "\n",
    "for j in range(20):\n",
    "    tmp = x_train_set[x_train_set['class'] == j + 1]\n",
    "    p_f[j,:] = 1   \n",
    "    for i in range(tmp.shape[0]):  \n",
    "        wdidx = tmp['wordIdx'].iloc[i]\n",
    "        count = tmp['count'].iloc[i]\n",
    "        p_f[j, wdidx - 1] += count\n",
    "    p_f[j,:] = p_f[j,:]/np.sum(p_f[j,:])\n",
    "    \n",
    "print('Probability Distribution:\\n', p_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_f(x_test, pi, p):\n",
    "    wdidx = x_test['wordIdx']\n",
    "    prob = [np.log(pi[j]) + np.sum(np.log(1 + x_test['count']) * np.log(p[j,wdidx - 1])) for j in range(20)]\n",
    "    pred = np.argmax(prob)\n",
    "        \n",
    "    return pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of smooth model on validation model is:\n",
      "96.05866177818515%\n",
      "The error rate for validation data is high. The reason why it is so high is because the validation set is too small. If you use the test data set, the error rate reduce to around 20.9%\n"
     ]
    }
   ],
   "source": [
    "result_f = []\n",
    "for i in range(y_validation_set.shape[0]):\n",
    "    x_test = x_validation_set.loc[x_validation_set['docIdx'] == i + 1,:]\n",
    "    pred_f, prob_f = decision_f(x_test, pi_f, p_f)\n",
    "    result_f.append(pred_f + 1 != y_validation_set['class'].iloc[i])\n",
    "    \n",
    "# calculate the error rate of this regular model\n",
    "error_rate_f = np.mean(result_f) * 100\n",
    "print('Error rate of smooth model on validation model is:\\n{}%'.format(error_rate_f))\n",
    "print('The error rate for validation data is high. The reason why it is so high is because the validation set is too small. If you use the test data set, the error rate reduce to around 20.9%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (ii) removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words from online\n",
    "stop_words = [\n",
    "\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \n",
    "\"again\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",    \n",
    "\"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"as\", \"at\", \"be\", \"became\", \"because\", \"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"behind\", \"being\", \"beside\", \"besides\", \"between\", \"beyond\", \"both\", \"but\", \"by\",\"can\", \"cannot\", \"cant\", \"could\", \"couldnt\", \"de\", \"describe\", \"do\", \"done\", \"each\", \"eg\", \"either\", \"else\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"find\",\"for\",\"found\", \"four\", \"from\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"indeed\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\",\"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\",\"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"she\", \"should\",\"since\", \"sincere\",\"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"take\",\"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\",\n",
    "\"this\", \"those\", \"though\", \"through\", \"throughout\",\n",
    "\"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\",\n",
    "\"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "\"very\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "\"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "\"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "\"who\", \"whoever\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "\"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all bad words\n",
    "vocabulary_data = vocabulary_data.reset_index() \n",
    "vocabulary_data['index'] = vocabulary_data['index'].apply(lambda x: x+1)\n",
    "total_list = set(vocabulary_data['index'])\n",
    "vocabulary_data = vocabulary_data[~vocabulary_data['word'].isin(stop_words)]\n",
    "good_list = vocabulary_data['index'].tolist()\n",
    "good_list = set(good_list)\n",
    "bad_list = total_list - good_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.001\n",
    "\n",
    "for bad in bad_list:\n",
    "    for j in range(20):\n",
    "        # a Laplace Smoothing with low ɑ for bad words\n",
    "        p_f[j][bad] = a/(np.sum(p_f[j,:]) + vocabulary_data.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_s(x_test, pi, p):\n",
    "    wdidx = x_test['wordIdx']\n",
    "    IDF = np.log(len(x_test['docIdx'].unique())/(x_test.groupby(['wordIdx'])['docIdx'].count()) + 1)\n",
    "    prob = [np.log(pi[j]) + np.sum(x_test['count'] * np.log(IDF * p[j,wdidx - 1])) for j in range(20)]\n",
    "    pred = np.argmax(prob)\n",
    "        \n",
    "    return pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of IDF model on validation data is:\n",
      "95.18790100824931%\n"
     ]
    }
   ],
   "source": [
    "result_s = []\n",
    "for i in range(y_validation_set.shape[0]):\n",
    "    x_test = x_validation_set.loc[x_validation_set['docIdx'] == i + 1,:]\n",
    "    pred_s, prob_s = decision_s(x_test, pi_f, p_f)\n",
    "    result_s.append(pred_s + 1 != y_validation_set['class'].iloc[i])\n",
    "    \n",
    "# calculate the error rate of this regular model\n",
    "error_rate_s = np.mean(result_s) * 100\n",
    "print('Error rate of IDF model on validation data is:\\n{}%'.format(error_rate_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate your final model on the test data. What error rate do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of naive Bayes model is:\n",
      "21.892071952031976%\n"
     ]
    }
   ],
   "source": [
    "# evaluate naive Bayes model on the test data\n",
    "\n",
    "result = []\n",
    "for i in range(y_test_label.shape[0]):\n",
    "    x_test = x_test_data.loc[x_test_data['docIdx'] == i + 1,:]\n",
    "    pred, prob = decision(x_test, pi, p)\n",
    "    result.append(pred + 1 != y_test_label['class'].iloc[i])\n",
    "    \n",
    "# calculate the error rate of naive Bayes model\n",
    "error_rate = np.mean(result) * 100\n",
    "print('Error rate of naive Bayes model is:\\n{}%'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of smooth model on test data is:\n",
      "20.919387075283144%\n"
     ]
    }
   ],
   "source": [
    "# evaluate smooth model on the test data\n",
    "\n",
    "result_f_test_data = []\n",
    "for i in range(y_test_label.shape[0]):\n",
    "    x_test = x_test_data.loc[x_test_data['docIdx'] == i + 1,:]\n",
    "    pred, prob = decision_f(x_test, pi, p)\n",
    "    result_f_test_data.append(pred + 1 != y_test_label['class'].iloc[i])\n",
    "    \n",
    "# calculate the error rate of naive Bayes model\n",
    "error_rate_f_test_data = np.mean(result_f_test_data) * 100\n",
    "print('Error rate of smooth model on test data is:\\n{}%'.format(error_rate_f_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate IDF model on the test data\n",
    "\n",
    "result_s_test_data = []\n",
    "for i in range(y_test_label.shape[0]):\n",
    "    x_test = x_test_data.loc[x_test_data['docIdx'] == i + 1,:]\n",
    "    pred, prob = decision_s(x_test, pi_f, p_f)\n",
    "    result_s_test_data.append(pred + 1 != y_test_label['class'].iloc[i])\n",
    "    \n",
    "# calculate the error rate of naive Bayes model\n",
    "error_rate_s_test_data = np.mean(result_s_test_data) * 100\n",
    "print('Error rate of IDF model on test data is:\\n{}%'.format(error_rate_s_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: We have evaluated 3 models on the test data, and it turns out that the smooth model performs a better accurate, whose error rate is 20.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 9 Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Handwritten digit recognition using a Gaussian generative model. In class, we mentioned the MNIST data set of handwritten digits. You can obtain it from:\n",
    "\n",
    "    http://yann.lecun.com/exdb/mnist/index.html\n",
    "    \n",
    " In this problem, you will build a classifier for this data, by modeling each class as a multivariate (784-dimensional) Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Upon downloading the data, you should have two training files (one with images, one with labels) and two test files. Unzip them. In order to load the data into Python you will find the following code helpful:\n",
    "\n",
    "    http://cseweb.ucsd.edu/~dasgupta/dse210/loader.py\n",
    "    \n",
    "#### For instance, to load in the training data, you can use:\n",
    "\n",
    "    x,y = loadmnist(’train-images-idx3-ubyte’, ’train-labels-idx1-ubyte’)\n",
    "    \n",
    "#### This will set x to a 60000 x 784 array where each row corresponds to an image, and y to a length-60000 array where each entry is a label (0-9). There is also a routine to display images: use displaychar(x[0]) to show the first data point, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(filename, source = 'http://yann.lecun.com/exdb/mnist/index.html'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "    \n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the inputs in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset = 16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data / np.float32(256)\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset = 8)\n",
    "    return data\n",
    "\n",
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "print('Shape of the train data:\\n', train_data.shape)\n",
    "print('\\nShape of the train labels:\\n', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first data point\n",
    "displaychar(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Split the training set into two pieces – a training set of size 50000, and a separate validation set of size 10000. Also load in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_data, train_labels\n",
    "\n",
    "# randomly select 50000 data from data set as training data set.\n",
    "random.seed(10)\n",
    "sel = random.sample(range (0, x.shape[0]), 50000 )\n",
    "x_train_data, y_train_data = train_data[sel,], train_labels[sel,]\n",
    "\n",
    "print('Shape of x_train_data:\\n', x_train_data.shape)\n",
    "print('\\nShape of y_train_data:\\n', y_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the remaining data as validation data set.\n",
    "remain = np.setdiff1d(range(0, x.shape[0]), sel)\n",
    "x_validation, y_validation = train_data[remain,], train_labels[remain,]\n",
    "\n",
    "print('Shape of x_validation:\\n', x_validation.shape)\n",
    "print('\\nShape of y_validation:\\n', y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "print('Shape of the test data:\\n', test_data.shape)\n",
    "print('\\nShape of the test labels:\\n', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Now fit a Gaussian generative model to the training data of 50000 points.\n",
    "\n",
    "• Determine the class probabilities.\n",
    "\n",
    "• Fit a Gaussian to each digit, by finding the mean and the covariance of the corresponding data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multivariabte Gaussian model\n",
    "\n",
    "def MultivariateGaussian(x, y):\n",
    "    #labels 1,2,...,k\n",
    "    k = 10  \n",
    "    \n",
    "    #number of features\n",
    "    d = (x.shape)[1]  \n",
    "    \n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    \n",
    "    for label in range(10):\n",
    "        indices = np.where(y == label)\n",
    "        indices = indices[0]\n",
    "        mu[label] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1)\n",
    "        pi[label] = float(len(indices))/float(len(y))\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mu, sigma, and pi\n",
    "mu, sigma, pi = MultivariateGaussian(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class probabilities:\\n', pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean of the corresponding data points:\\n ', mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariance of the corresponding data points:\\n ', sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) One last step is needed: it is important to smooth the covariance matrices, and the usual way to do this is to add in cI, where c is some constant and I is the identity matrix. What value of c is right? Use the validation set to help you choose. That is, choose the value of c for which the resulting classifier makes the fewest mistakes on the validation set. What value of c did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify funtion using Bayes' rule\n",
    "\n",
    "def decision(x, pi, mu, sigma): \n",
    "    prob = np.zeros((10, x.shape[0]))\n",
    "    \n",
    "    for i in range (0,10):\n",
    "        prob[i,:] = pi[i]* multivariate_normal.pdf(x, mean = mu[i,:], cov = sigma[i,:,:])                                             \n",
    "        #if the sigma matrix cannot be inversed, we need to add a np.eye() to avoid singular matrix error.\n",
    "        #since we will smooth in step (d), so I didn't use np.eye() here.\n",
    "        #prob[i,:] = pi[i]* multivariate_normal.pdf(x, mean = mu[i,:], cov = sigma[i,:,:] + np.eye(sigma.shape[1],sigma.shape[2]))\n",
    "\n",
    "    pred = np.argmax(prob, axis = 0)\n",
    "\n",
    "    return pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set c as a constant and I as the identity matix\n",
    "# randomly give c a number\n",
    "c = 0.1\n",
    "iden = np.zeros((10,784,784))\n",
    "\n",
    "for i in range (0,10) :\n",
    "    iden[i,:,:] = np.diag([1] * 784) \n",
    "\n",
    "# smooth the covariance matrix\n",
    "decision(x_validation[:5,], pi, mu, sigma + c * iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_grid = np.linspace(0.01, 0.3, num=20 )\n",
    "validation_error =[]\n",
    "\n",
    "for c in c_grid:\n",
    "    pred = decision(x_validation, pi, mu, sigma + c * iden)[0]\n",
    "    validation_error.append(1 - np.mean(pred == y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller erorr is desired\n",
    "plt.plot(c_grid,validation_error)\n",
    "\n",
    "# find the optimal c value\n",
    "c_optim = c_grid[np.argmin(validation_error)]\n",
    "\n",
    "print('The optimal of c is:\\n', np.min(validation_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Turn in an iPython notebook that includes:\n",
    "\n",
    "    • All your code.\n",
    "    \n",
    "    • Error rate on the MNIST test set.\n",
    "    \n",
    "    • Out of the misclassified test digits, pick five at random and display them. For each instance, list the posterior probabilities Pr(y|x) of each of the ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the error rate on the MNIST test set.\n",
    "accuracy = np.mean(decision(test_data, pi, mu, sigma + c_optim * iden)[0] == test_labels)\n",
    "error_rate = (1 - accuracy)*100\n",
    "\n",
    "print('Error rate on the MNIST test set:\\n{}%'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, prob = decision(test_data,pi, mu, sigma + c_optim * iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis = np.where(pred != test_labels)[0]\n",
    "random.seed(14)\n",
    "\n",
    "for i in random.sample(range(0,len(mis)),5):\n",
    "    print('posterior probabilities are:\\n', prob[:,mis[i]]/np.sum(prob[:,mis[i]]))\n",
    "    #print(np.where(np.argmax(prob[:,mis[i]]/np.sum(prob[:,mis[i]]))))\n",
    "    print('\\nmissclassified digits', test_labels[mis[i]])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 10 Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we’ll be using the animals with attributes data set. Go to \n",
    "\n",
    "    http://attributes.kyb.tuebingen.mpg.de\n",
    "    \n",
    "and, under “Downloads”, choose the “base package” (the very first file in the list). Unzip it and look over the various text files.\n",
    "\n",
    "About the dataset: This is a small dataset that has information on about 50 animals. The animals are listed in classes.txt. For each animal, the information consists of values for 85 features: does the animal have a tail, is it slow, does it have tusks, etc. The details of the features are in the predicates.txt. The full data consists of a 50 x 85 matrix of real values, in predicate-matrix-continuous.txt. There is also a binarized version of this data, in predicate-matrix-binary.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(filename, source = 'http://attributes.kyb.tuebingen.mpg.de'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "    \n",
    "def load_data(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with bz2.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset = 16)\n",
    "    return data / np.float32(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_package_data = load_data('AwA-base.tar.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Load the real-valued array, and also the animal names, into Python. Run k-means on the data (from sklearn.cluster) and ask for k = 10 clusters. For each cluster, list the animals in it. Does the clustering make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes with animal names.\n",
    "classes_with_animal_names = pd.read_fwf(\"Animals_with_Attributes/classes.txt\", header = None)[1].values\n",
    "print('Shape of the classes.txt:\\n', classes_with_animal_names.shape, '\\n')\n",
    "print('Data of the classes.txt:\\n', classes_with_animal_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicates with feature names.\n",
    "predicates_with_feature_names = pd.read_fwf(\"Animals_with_Attributes/predicates.txt\", header = None)[1].values\n",
    "print('Shape of the predicates.txt:\\n', predicates_with_feature_names.shape, '\\n')\n",
    "print('Data of the predicates.txt:\\n', predicates_with_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of real values.\n",
    "predicate_matrix = pd.read_fwf(\"Animals_with_Attributes/predicate-matrix-continuous.txt\", header = None).values\n",
    "print('Shape of the predicate-matrix-continuous.txt:\\n', predicate_matrix.shape, '\\n')\n",
    "print('Data of the predicate-matrix-continuous.txt:\\n', predicate_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names (feature names) for the predicate matrix of the real value.\n",
    "classes_features = pd.DataFrame(data = predicate_matrix, columns = predicates_with_feature_names)\n",
    "\n",
    "# add row index for predicate matrix of the real value.\n",
    "classes_features.index = classes_with_animal_names\n",
    "print('Shape of classes_features:\\n', classes_features.shape, '\\n')\n",
    "print('Data of classes_features:\\n', classes_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means on the data, with k = 10.\n",
    "kmeans = KMeans(n_clusters = 10, init = 'k-means++',  n_init = 10)\n",
    "kmeans.fit(predicate_matrix, classes_with_animal_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label all animals\n",
    "print('labels for animals:\\n',kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster animals to their labels\n",
    "\n",
    "clustering = {i:[] for i in range(0,10)}\n",
    "\n",
    "for i,j in enumerate(classes_with_animal_names):\n",
    "    clustering[kmeans.labels_[i]].append(j)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print('label =',i,'\\n')\n",
    "    print('animals:',clustering[i],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion for (a):\n",
    "\n",
    "#### Does the clustering make sense?\n",
    "#### --- Yes, it makes some sense.\n",
    "#### --- From the clustering above, we can see that pets in label 7 are grouped close together as well as other labels. \n",
    "#### --- However, it is not perfect. we need to figure out optimal k or find other algorithms to cluster these animals better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Now hierarchically cluster this data, using scipy.cluster.hierarchy.linkage. Choose Ward’s method, and plot the resulting tree using the dendrogram method, setting the orientation parameter to ‘right’ and labeling each leaf with the corresponding animal name. You will run into a problem: the plot is too cramped because the default figure size is so small. To make it larger, preface your code with the following:\n",
    "           from pylab import rcParams\n",
    "           rcParams[’figure.figsize’] = 5, 10\n",
    "#### (or try a different size if this doesn’t seem quite right). Does the hierarchical clustering seem sensible to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scipy.cluster.hierarchy.linkage to hierarchically cluster this data.\n",
    "hierarchically_cluster_link = linkage(predicate_matrix, method = 'ward');\n",
    "\n",
    "# use dendrogram method to plot the resulting tree.\n",
    "dendrogram(hierarchically_cluster_link, orientation = \"right\", labels = classes_with_animal_names)\n",
    "\n",
    "# resize the figure\n",
    "rcParams['figure.figsize'] = [40,40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion for (b):\n",
    "\n",
    "#### Does the hierarchical clustering seem sensible to you?\n",
    "#### --- Yes, it seems sensible to me.\n",
    "#### --- For choosing the linkage, Ward’s method is the sensible default. It groups based on reducing the sum of squared distances of each observation from the average observation in a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Turn in an iPython notebook with a transcript of all this experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See above for all this experimentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
